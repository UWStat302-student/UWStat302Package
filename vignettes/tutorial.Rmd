---
title: "Project 3: UWStat302Package Tutorial"
author: "UWStat302 Student"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{UWStat302Package Tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(UWStat302Package)

library("gapminder")
library("tidyverse")
library(ggplot2)
library(kableExtra)
library(randomForest)
library(stats)
library(class)
```

Install \texttt{UWStat302Package} using:

```{r, eval = FALSE}
devtools::install_github("UWStat302-student/UWStat302Package", build_vignette = TRUE, build_opts = c())
```

# Tutorial for my_pow

```{r, eval = FALSE}
my_t.test(my_gapminder$lifeExp, "two.sided", 60)  # P = 0.09322877
my_t.test(my_gapminder$lifeExp, "less", 60)       # P = 0.04661438
my_t.test(my_gapminder$lifeExp, "greater", 60)    # P = 0.9533856
```
The first line of code evaluate the following hypothesis test:  
$H_0: \mu = 60$   
$H_a: \mu \neq 60$   
With $\alpha = 0.05$ and $P = 0.0932$, we cannot draw a conclusion from this result.  
The second line of code evaluate the following hypothesis test:  
$H_0: \mu = 60$   
$H_a: \mu < 60$   
With $\alpha = 0.05$ and $P = 0.0466$, we reject $H_0$ in favor of $H_a$ that the observed mean is less than 60.
The third line of code evaluate the following hypothesis test:  
$H_0: \mu = 60$   
$H_a: \mu \neq 60$   
With $\alpha = 0.05$ and $P = 0.953$, we have a `p-value` larger than $\alpha = 0.05$, we cannot draw a conclusion from this result.



# Tutorial of lm
```{r}
test <- lm(lifeExp ~ gdpPercap + continent, data = gapminder)
my_coef <- test[[1]]
my_matrix <- model.matrix(lifeExp ~ gdpPercap + continent, data = gapminder)
y_hat <- my_matrix %*% as.matrix(my_coef)
my_data <- data.frame("Actual" = gapminder$lifeExp,
                      "Fitted" = y_hat,
                      "Continent" = gapminder$continent)
ggplot(my_data,aes(x = Actual, y = Fitted, color = Continent)) + 
  geom_point() + theme_bw(base_size = 12) + 
  labs(title = "Actual vs. Fitted values",
       caption = "Graph 1") + 
  theme(plot.title = element_text(hjust = 0.5),
        plot.caption = element_text(hjust = 0.5)
)
coeff <- formatC(test$Estimate[2], digit = 3)
pval <- formatC(test$Pr...t..[2], digit = 3)
```

The coefficient of `gdpPercap` of the regression model is `r coeff`. This tells us that there is a positive but not strong relation between `gdpPercap` and `lifeExp`.  
The `p-value` for the coefficient of `gdpPercap` is `r pval`, which is less than $\alpha = 0.05$, telling us that we can reject the null hypothesis "coefficient of `gdpPercap` $= 0$" in favor of the alternative hypothesis: `gdpPercap` is statistically significant for interpreting `lifeExp`.  
Graph 1 is the plot of Actual value vs. Fitted value, and the fitted values match the actual values well. The curved shapes demonstrate a non-linear growth of `lifeExp` at a high `gdpPercap`


# Tutorial of knn_cv

```{r}
k_cv <- 5
cv_err <- rep(NA, k_cv)
train_err <- rep(NA, k_cv)
for (i in 1:10) {
  my_knn <- knn.cv(cbind(gapminder[, 4], gapminder[,6]), 
                     gapminder$continent, i, k_cv)
  cv_err[i] <- my_knn[[2]]
  train_err[i] <- my_knn[[3]]
}
  my_err <- data.frame("knn" = c(1:10),
                       "Training Error" = train_err,
                       "CV Error" = cv_err)
  kable(my_err)
```
Based on the training error, I will choose the model with `k_nn` $= 1$ because it has no error. However, if I look at CV misclassification rate, I will choose the model with `k_nn` $= 7$ because the CV misclassification rate steadily decreases when `k_nn` goes from $1$ to $7$ and starts to fluctuates after $7$.  
In practice, I will choose `k_nn`$= 7$. From the lecture, we know that `k_nn` $= 1$ always gives the smallest error on training datasets, which is the result from overfitting, and the training error steadily increases as we increase the value of `k_nn`. The test error, on the other hand, has a U-shape as we increasing the value of `k_nn`. By using cross-validation, we are able to test our model on all data, and thus identify the optimal `k_nn` value which minimize the test error. Therefore, in this case, the model with `k_nn` $= 7$ avoids overfitting as well as gives a good prediction.  
